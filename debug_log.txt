====================嗨嗨嗨我又来了啊====================
Log_num: 1
Date: 2023.03.09
Time: 13:41
Contents:
	1). Rename 'ActorNetwork' to 'Actor', 'CriticNetwork' to 'Critic'
	2). Move files in ./simulation/PG_based/ to ./simulation/AC_based/
	3). Add basic classes 'ProbActor' and 'DualCritic' in ./common/common_cls.py
	4). Fix some bugs caused by 1), 2), and 3)
=================奥利给兄弟们干他就完了=================
	

====================嗨嗨嗨我又来了啊====================
Log_num: 2
Date: 2023.03.10
Time: 00: 17
Contents:
	1). Add SAC
	2). Add SAC-4-CartPole.py in /simulation/AC_based/
=================奥利给兄弟们干他就完了=================
	

====================嗨嗨嗨我又来了啊====================
Log_num: 3
Date: 2023.03.11
Time: 19:24
Contents:
	1). Add a new environment: CartPoleAngleOnly. 
		This new environment only takes angular information as the states of RL.
		We don't care the positional state of the cartpole.
	2). Add SAC-4-CartPoleAngleOnly.py in /simulation/AC_based/
	3). Add TD3-4-CartPoleAngleOnly.py in /simulation/AC_based/
	4). Add a well-trained controller for CartPoleAngleOnly using TD3 in /datasave/networks/TD3-CartPoleAngleOnly/parameters
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 4
Date: 2023.03.11
Time: 19:50
Contents:
	1). Discard the return variables of function 'step_update(action)' in all envs.
	2). Add different directories for different RL algorithms in /simulation/AC_based
=================奥利给兄弟们干他就完了=================

	
====================嗨嗨嗨我又来了啊====================
Log_num: 4
Date: 2023.03.11
Time: 20:57
Contents:
	1). Fix some tiny bugs.
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 5
Date: 2023.03.13
Time: 20:54
Contents:
	1). Add A2C.
	2). Add A2C-4-CartPoleDiscreteAngleOnly.py in /simulation/AC_based/A2C/
	3). Fix some bugs.
注：
    破玩意不好使，我怀疑是我写的有问题，后来从 github 上找了两个 demo，然后用 ChatGPT 也生成了一个demo，都不好使。
    A2C 用来控制 gym 那个cartpole-v1 有点作用，但是动作选择才两个，我就是盲猜都有 50% 的概率，还用它学。
    我自己写的 CartPoleDiscreteAngleOnly 环境的动作最开始是33个选择，后来13个，最后7个；角度范围从30度，缩小到20度，最后是10度，都不好使。
    相当于我把正确答案都送到它嘴边了，都尼玛学不出来。
    反观TD3，连续动作空间，经验池采20000左右，1分钟不到直接完美......还是得使用经验池啊..>_<
Tips:
    The darn thing doesn't work. I suspect there's something wrong with my code.
    Later, I found two demos on GitHub and a demo generated by ChatGPT. The three demos didn't work either.
    A2C works a bit for controlling gym's cartpole-v1, but it only has two actions.
    I'm just guessing with a 50% chance.
    I created my own CartPoleDiscreteAngleOnly environment with initially 33 action choices, then reduced to 13, and finally 7;
    The angle range went from 30 degrees to 20 degrees to 10 degrees, but none of them worked. God...
    It's as if I've handed it the correct answer on a silver platter, and it still can't learn.
    On the other hand, TD3 with a continuous action space and an experience pool of around 20,000 can learn perfectly in less than a minute...
    I guess I still need to use the replay buffer.
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 6
Date: 2023.03.14
Time: 20:54
Contents:
	1). Add a controller for CartPole with A2C.
Tips:
    This environment is different the one in gym. There are two main difference.
    First, the action of the CartPole in gym is discrete, while main is continuous.
    Then, the training goal of the CartPole in gym is just stabilizing the Pole,
        while main is stabilizing the Pole and maintaining the Cart at x=0 simultaneously.
    However, the performance is worse than just stabilizing the Pole
        because the Pole and the Cart have conflict of interest in some scenarios.
    I insist that controlling both Cart and Pole is more meaningful and challengeable
        and that is what DRL should do.
    Currently, my controller can stabilize the Pole but leave the Cart keeps fluctuating around x=0.
    目前摆能稳定住，但是小车在搁那嘎达晃晃悠悠的。(不是动力学的问题，我加了阻力，所以理论上有能量耗散，绝对可以稳住不动的)
    If anyone happens to see my code and has any idea to improve the performance, please email me.
        E-mail: yefeng.yang@connect.polyu.hk
        Respect~ 瑞思拜~
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 7
Date: 2023.03.15
Time: 19:48
Contents:
	1). Add PPO.
	2). Add a controller for CartPoleAngleOnly using PPO.
	3). Add a controller for FlightAttitudeSimulator2StateContinuous using PPO.
Tips:
    The performance is pretty good.
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 7
Date: 2023.03.16
Time: 11:28
Contents:
	1). Add PPO-4-CartPole.py
	2). PPO-4-UGVBidirectional.py
Tips:
    No well-trained controller for the two envs yet.
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 8
Date: 2023.03.21
Time: 20:26
Contents:
	1). Add DPPO
	2). Add DPPO-4-CartPoleAngleOnly.py
	3). Add a controller for CartPoleAngleOnly using DPPO.
	4). Add DPPO-4-FlightSimulator2State.py
	5). Add a controller for FlightSimulator2State using DPPO.
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 9
Date: 2023.03.23
Time: 21:38
Contents:
	1). Add DPPO2 (without debugging)
=================奥利给兄弟们干他就完了=================


====================嗨嗨嗨我又来了啊====================
Log_num: 10
Date: 2023.03.28
Time: 22:43
Contents:
	Nothing, just remind that, DPPO2 doesn't work!!

Tips: 疯了，一周白干，DPPO2 不好使，不知道是哪里的代码出问题了。
    DPPO2 使用了 python 较新的 shared_memory 作为通信机制，这样做快，我对比了一个 github上 用 pipe 的，真的是快的特别多，
    但是这会和 CUDA 的多进程冲突，所以只能用 CPU。但是当我只开一个进程的时候，训练完全没有效果，而同样的环境，用 PPO 秒收敛。
    用 DPPO1，因为我减小了学习率，前期因为 agent 太多，收敛也不容易，所以 DPPO1 收敛地比 PPO 慢很多，但是很稳，最后效果相同。
    所以，肯定不是 DPPO2 网络训练问题，应该是中间某个环节的数据传输出问题了 (多进程通信，包括探索的数据通信，网络参数通信，等等)。
    github 上没有找到用 shared_memory 写的 (虽然我坚持认为这么做最科学，但是 mp.shared_memory 好像是 python3.8 之后的，所以可能暂时没有这么写的)。
    debug 到吐，最后也没查出来是谁的问题。。。
    哪位大佬碰巧看到，可以浏览一下 /algorithm/policy_base/Distributed_PPO2.py 和 /simulation/POlicy_based/DPPO2-4-CartPoleAngleOnly.py 这俩是对应的。
    多谢大佬...... >_< Q_Q T_T
=================奥利给兄弟们干他就完了=================